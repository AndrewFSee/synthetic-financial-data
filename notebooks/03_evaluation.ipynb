{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 â€” Evaluation\n",
    "\n",
    "Evaluate and compare generative models using statistical tests, stylized facts, TSTR, and privacy metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from synfin.evaluation.statistical_tests import ks_test, mmd_rbf\n",
    "from synfin.evaluation.stylized_facts import check_all_stylized_facts\n",
    "from synfin.evaluation.tstr import tstr_benchmark\n",
    "from synfin.evaluation.metrics import compute_all_metrics\n",
    "\n",
    "print('Evaluation tools loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy real and synthetic data for demonstration\n",
    "np.random.seed(42)\n",
    "real = np.random.randn(300, 30, 8).astype(np.float32)\n",
    "synthetic = np.random.randn(300, 30, 8).astype(np.float32) * 1.05\n",
    "\n",
    "feature_names = ['Open', 'High', 'Low', 'Close', 'Volume', 'LogReturn', 'LogVolume', 'DollarVolume']\n",
    "\n",
    "# Run KS tests\n",
    "real_flat = real.reshape(-1, 8)\n",
    "synth_flat = synthetic.reshape(-1, 8)\n",
    "ks_results = ks_test(real_flat, synth_flat, feature_names)\n",
    "\n",
    "print('KS Test Results:')\n",
    "for feat, res in ks_results.items():\n",
    "    status = 'PASS' if res['p_value'] > 0.05 else 'FAIL'\n",
    "    print(f'  {feat:20s}: stat={res[\"statistic\"]:.3f}, p={res[\"p_value\"]:.3f} [{status}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MMD\n",
    "mmd = mmd_rbf(real_flat, synth_flat)\n",
    "print(f'MMD: {mmd:.4f}')\n",
    "\n",
    "# Full evaluation\n",
    "report = compute_all_metrics(real, synthetic, feature_names=feature_names, run_tstr=True)\n",
    "print(f'\\nOverall Realism Score: {report[\"realism_score\"]:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
